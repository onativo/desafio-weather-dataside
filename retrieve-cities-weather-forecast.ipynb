{"cells":[{"cell_type":"markdown","metadata":{"id":"580dd39c-f066-4c32-af47-648eb71f5918","tags":[]},"source":["# Desafio: Consumo de Dados para Previsão do Tempo das Cidades do Vale do Paraíba.\n","\n","## Objetivo\n","\n","Avaliar conhecimentos nas linguagens Python e SQL e na engine de processamento Apache Spark.\n","\n","## Descrição\n","\n","Neste desafio, você desenvolverá um notebook que será responsável por extrair dados de previsão do tempo das cidades do Vale do Paraíba, região onde se localiza a Dataside. Para consultar todas as cidades dessa região, utilizaremos a API do IBGE. No caso, basta realizar uma requisição HTTP com o método GET, utilizando a URL abaixo:\n","\n","```\n","https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios\n","```\n","\n","Com esses dados, gerar um data frame e a partir dele uma temp view. Ex: \"cities\"\n","\n","Utilizando os nomes das cidades, deverão ser consultados os dados de previsão de tempo para cada cidade. Para realizar essa consulta, poderá ser utilizada qualquer uma das APIs informadas no link abaixo.\n","\n","[Public APIs - Wather](https://github.com/public-apis/public-apis#weather)\n","\n","Obs.: Para algumas, pode ser necessário cadastrar-se para acessar sua API Key. Mas nenhuma delas deve precisar cadastrar cartão de crédito ou adicionar qualquer valor monetário para utilizar. Caso alguma solicite, basta optar por outra.\n","\n","Com os dados consultados, gerar um data frame e partir dele outra temp view. Ex: \"forecasts\"\n","\n","Com as temp views geradas, utilizar Spark SQL para criar queries e gerar data frames das seguintes tabelas:\n","\n","- Tabela 1: dados de previsão do tempo para os próximos cinco dias, para cada data e cidade consultadas. As colunas dessa tabela serão:\n","    - Cidade\n","    - CodigoDaCidade\n","    - Data\n","    - Regiao\n","    - Pais\n","    - Latitude\n","    - Longigute\n","    - TemperaturaMaxima\n","    - TemperaturaMinima\n","    - TemperaturaMedia\n","    - VaiChover\n","    - ChanceDeChuva\n","    - CondicaoDoTempo\n","    - NascerDoSol\n","    - PorDoSol\n","    - VelocidadeMaximaDoVento\n","    \n","    Obs.: Os valores da coluna \"VaiChover\" deverá ser \"Sim\" ou \"Não\". E a coluna \"CodigoDaCidade\" é o ID retornado junto com os nomes da cidades na API do IBGE.\n","    Obs.: Dependendo da API utilizada, algumas colunas podem não existir e ficarão em branco. Você deve optar por uma API que traga o maior número de informações possível.\n","\n","- Tabela 2: quantidade de dias com chuva e sem chuva para os dias consultados, para cada data consultada. Colunas:\n","    - Cidade\n","    - QtdDiasVaiChover\n","    - QtdDiasNaoVaiChover\n","    - TotalDiasMapeados\n","\n","Essas tabelas deverão ser exportadas em formado CSV e entregue no final do desafio.\n","\n","## To Do\n","\n","[ ] - Consultar municípios do Vale do Paraíba, gerar um data frame e criar uma temp view com esses dados.\n","[ ] - Consultar dados do tempo para cada município, gerar um data frame e criar uma outra temp view.\n","[ ] - Utilizar Spark SQL para gerar os data frames das Tabelas 1 e 2.\n","[ ] - Exportar os data frames para CSV.\n","\n","## Atenção\n","\n","- Existe um limite de requisições de 10000 requests por conta cadastrada na m3o.\n","- Essa API pode retornar cidades de outras regiões que possuem nome semelhante a alguma cidade do Vale do Paraiba. Pode mantê-las ou filtrar para gerar as tabelas apenas com dados de Regiao = Sao Paulo. Fica a seu critério.\n","\n","## Entregando o desafio\n","\n","Concluindo todos os passos informados em To Do, basta salvar o arquivo .ipynb do notebook e enviar para a Dataside juntamente com os CSVs das duas tabelas.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjfsduipH7tW","outputId":"b98ae981-c028-45e6-aaab-29e36cb95bed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\n","Collecting pyspark\n","\n","  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n","\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\n","Collecting py4j==0.10.9.5\n","\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\n","  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=a48b7d22dcd2b5a0948cc3b7bf20b941f354fdcfacaf75771af7184f5a5b79df\n","\n","  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n","\n","Successfully built pyspark\n","\n","Installing collected packages: py4j, pyspark\n","\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\n","Collecting findspark\n","\n","  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n","\n","Installing collected packages: findspark\n","\n","Successfully installed findspark-2.0.1\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","\n","Collecting unidecode\n","\n","  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n","\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\n","\u001b[?25hInstalling collected packages: unidecode\n","\n","Successfully installed unidecode-1.3.6\n"]}],"source":["!pip install pyspark\n","!pip install findspark\n","!pip install unidecode"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a1cb6c40-3073-43b0-b7f4-95e7c9dd8245","tags":[]},"outputs":[],"source":["import findspark\n","findspark.init()\n","\n","import requests\n","import json\n","import unidecode\n","import ast\n","import pyspark\n","from pyspark import SQLContext\n","from pyspark.sql import SparkSession\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import *\n","from pyspark.sql.types import StructType, StructField, StringType\n","\n","\n","\n","spark = SparkSession.builder \\\n","      .master(\"local[1]\") \\\n","      .appName(\"SparkByExamples.com\") \\\n","      .getOrCreate()\n","sparkContext = spark.sparkContext"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOaPnVCgjlJM","outputId":"70b156bf-9ac5-4b5e-e788-52b7c11eae0a"},"outputs":[{"data":{"text/plain":["200"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#faz request na api e retorna json com dados\n","r = requests.get('https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios')\n","#verifica se 200 para sucesso\n","r.status_code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tu3qFVH1MmOr"},"outputs":[],"source":["#adiciona os dados retornados na variável cities\n","raw_cities = r.json()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm7vIWDRB90G","outputId":"e4854232-ee5b-4fbe-9ba4-aea4107f9d86"},"outputs":[{"data":{"text/plain":["dict_items([('id', 3502507), ('nome', 'Aparecida'), ('microrregiao', {'id': 35051, 'nome': 'Guaratinguetá', 'mesorregiao': {'id': 3513, 'nome': 'Vale do Paraíba Paulista', 'UF': {'id': 35, 'sigla': 'SP', 'nome': 'São Paulo', 'regiao': {'id': 3, 'sigla': 'SE', 'nome': 'Sudeste'}}}}), ('regiao-imediata', {'id': 350052, 'nome': 'Guaratinguetá', 'regiao-intermediaria': {'id': 3511, 'nome': 'São José dos Campos', 'UF': {'id': 35, 'sigla': 'SP', 'nome': 'São Paulo', 'regiao': {'id': 3, 'sigla': 'SE', 'nome': 'Sudeste'}}}})])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["raw_cities[0].items()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vQd6rI7Avcy","outputId":"095c2813-7be9-4124-a88c-284f57f7c063"},"outputs":[{"data":{"text/plain":["3502507"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["raw_cities[0]['id']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pklFxXx8CP6J","outputId":"f3f47575-9792-4efc-80ce-959aaf38fe8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----+-----------+-----------+---+------+\n","\n","| id|nome|microregiao|mesorregiao| UF|regiao|\n","\n","+---+----+-----------+-----------+---+------+\n","\n","+---+----+-----------+-----------+---+------+\n","\n","\n"]}],"source":["#cria dataframe com colunas para os dados da consulta\n","emptyRDD = spark.sparkContext.emptyRDD()\n","\n","schemaDF1 = (StructType([\n","    StructField('id', LongType(), True),\n","    StructField('nome', StringType(), True),\n","    StructField('microregiao', StringType(), True),\n","    StructField('mesorregiao', StringType(), True),\n","    StructField('UF', StringType(), True),\n","    StructField('regiao', StringType(), True)\n","]))\n","df = spark.createDataFrame(emptyRDD, schemaDF1)\n","df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qo8xPYdMEi2n"},"outputs":[],"source":["for city in raw_cities:\n","  newRow = spark.createDataFrame([(city['id'],\n","                                   city['nome'],\n","                                   city['microrregiao']['nome'],\n","                                   city['microrregiao']['mesorregiao']['nome'],\n","                                   city['microrregiao']['mesorregiao']['UF']['sigla'],\n","                                   city['microrregiao']['mesorregiao']['UF']['regiao']['nome']\n","                                   )])\n","  df = df.union(newRow)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7L4nISOMNFI","outputId":"2a12645b-1552-4522-8ac7-2cbcb6a46e24"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+------------------+--------------------+------------------------+---+-------+\n","\n","|id     |nome              |microregiao         |mesorregiao             |UF |regiao |\n","\n","+-------+------------------+--------------------+------------------------+---+-------+\n","\n","|3502507|Aparecida         |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3503158|Arapeí            |Bananal             |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3503505|Areias            |Bananal             |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3504909|Bananal           |Bananal             |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3508504|Caçapava          |São José dos Campos |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3508603|Cachoeira Paulista|Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3509700|Campos do Jordão  |Campos do Jordão    |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3509957|Canas             |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3510500|Caraguatatuba     |Caraguatatuba       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3513405|Cruzeiro          |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3513603|Cunha             |Paraibuna/Paraitinga|Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3518404|Guaratinguetá     |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3520202|Igaratá           |São José dos Campos |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3520400|Ilhabela          |Caraguatatuba       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3524402|Jacareí           |São José dos Campos |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3524907|Jambeiro          |Paraibuna/Paraitinga|Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3526308|Lagoinha          |Paraibuna/Paraitinga|Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3526605|Lavrinhas         |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3527207|Lorena            |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","|3531704|Monteiro Lobato   |Campos do Jordão    |Vale do Paraíba Paulista|SP |Sudeste|\n","\n","+-------+------------------+--------------------+------------------------+---+-------+\n","\n","only showing top 20 rows\n","\n","\n"]}],"source":["df.show(truncate = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WuKa93Y2Gh0Y","outputId":"8db4dc7e-2c3b-4c37-ffa3-e7388d4b75d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+\n","\n","|              nome|\n","\n","+------------------+\n","\n","|         Aparecida|\n","\n","|            Arapeí|\n","\n","|            Areias|\n","\n","|           Bananal|\n","\n","|          Caçapava|\n","\n","|Cachoeira Paulista|\n","\n","|  Campos do Jordão|\n","\n","|             Canas|\n","\n","|     Caraguatatuba|\n","\n","|          Cruzeiro|\n","\n","|             Cunha|\n","\n","|     Guaratinguetá|\n","\n","|           Igaratá|\n","\n","|          Ilhabela|\n","\n","|           Jacareí|\n","\n","|          Jambeiro|\n","\n","|          Lagoinha|\n","\n","|         Lavrinhas|\n","\n","|            Lorena|\n","\n","|   Monteiro Lobato|\n","\n","+------------------+\n","\n","only showing top 20 rows\n","\n","\n"]}],"source":["#create a temporary table view from original DataFrame\n","df.createOrReplaceTempView('cities')\n","#select data from temp view\n","spark.sql('select nome from cities').show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAz5gXxIat3S","outputId":"4d717dcb-e098-4c00-8c51-29c0e070c3fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Aparecida', 'Arapeí', 'Areias', 'Bananal', 'Caçapava', 'Cachoeira Paulista', 'Campos do Jordão', 'Canas', 'Caraguatatuba', 'Cruzeiro', 'Cunha', 'Guaratinguetá', 'Igaratá', 'Ilhabela', 'Jacareí', 'Jambeiro', 'Lagoinha', 'Lavrinhas', 'Lorena', 'Monteiro Lobato', 'Natividade da Serra', 'Paraibuna', 'Pindamonhangaba', 'Piquete', 'Potim', 'Queluz', 'Redenção da Serra', 'Roseira', 'Santa Branca', 'Santo Antônio do Pinhal', 'São Bento do Sapucaí', 'São José do Barreiro', 'São José dos Campos', 'São Luiz do Paraitinga', 'São Sebastião', 'Silveiras', 'Taubaté', 'Tremembé', 'Ubatuba']\n"]}],"source":["#collect data from temp view to loop through\n","dataCollect = spark.sql('select nome from cities').collect()\n","cities_name = []\n","\n","#stores the names of the cities in the cities_name list to pass to API\n","for city in dataCollect:\n","  cities_name.append(city['nome'])\n","  \n","print(cities_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADTLe7cmX-ko"},"outputs":[],"source":["API_KEY = ''\n","latitudes = []\n","longitudes = []\n","\n","#get city latitude and longitude from city name and state code\n","for city in cities_name:\n","  get_coordinates = requests.get(f'http://api.openweathermap.org/geo/1.0/direct?q={city},BR&limit=5&appid={API_KEY}')\n","  raw_data = json.loads(get_coordinates.text)\n","   \n","  latitudes.append(raw_data[0]['lat'])\n","  longitudes.append(raw_data[0]['lon'])\n","\n","#link_api = f'api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={API_KEY}'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e3OEq98YgoS"},"outputs":[],"source":["#convert list of latitudes to a dataframe\n","latitudes_data = spark.createDataFrame([(lat,) for lat in latitudes], ['latitudes'])\n","\n","#convert list longitudes to a dataframe\n","longitudes_data = spark.createDataFrame([(lon,) for lon in longitudes], ['longitudes'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pF2HJ8DEZdHB"},"outputs":[],"source":["from pyspark.sql.functions import monotonically_increasing_id, row_number\n","from pyspark.sql import Window\n","\n","#add sequential index and join both dataframes to get intermediary result\n","latitudes_data = latitudes_data.withColumn(\"index\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n","longitudes_data = longitudes_data.withColumn(\"index\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n","\n","#intermediary result of both latitude and longitude dataframes\n","intermediary_df = latitudes_data.join(longitudes_data, latitudes_data.index == longitudes_data.index).drop('index')\n","\n","#intermediary_df.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i91MkQCwaTYw"},"outputs":[],"source":["#now, to join the main df to the intermediary_df\n","\n","#add sequential index in both dataframes\n","df = df.withColumn('index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n","intermediary_df = intermediary_df.withColumn('index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n","\n","#final result\n","complete_df = df.join(intermediary_df, df.index == intermediary_df.index).drop('index')\n","\n","#complete_df.show(truncate = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4cqG7f3shPh"},"outputs":[],"source":["#rows = complete_df.count()\n","#print(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sqx8G453bCIA","outputId":"424d61e6-04d2-4a15-eb50-425e949ccc64"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------+-----------+\n","\n","|  latitudes| longitudes|\n","\n","+-----------+-----------+\n","\n","| -22.851552|-45.2340924|\n","\n","|-22.6738889|-44.4477778|\n","\n","|-22.5800929|-44.6975127|\n","\n","|-22.6828195|-44.3221095|\n","\n","| -23.099204| -45.707645|\n","\n","| -22.666498| -45.015384|\n","\n","|-22.7395263|-45.5912829|\n","\n","|-22.7029347|-45.0526508|\n","\n","|  -23.62028|  -45.41306|\n","\n","|-22.5783685|-44.9642044|\n","\n","|  -23.07753|-44.9567436|\n","\n","|-22.8057839|-45.1908926|\n","\n","|-23.2063475| -46.156934|\n","\n","| -23.816628| -45.368685|\n","\n","|  -23.30528|  -45.96583|\n","\n","|-23.2556416|-45.6919926|\n","\n","|-23.0898337|-45.1903825|\n","\n","| -22.570047| -44.902359|\n","\n","|-22.7367652|-45.1070876|\n","\n","|-22.9553542|-45.8387146|\n","\n","+-----------+-----------+\n","\n","only showing top 20 rows\n","\n","\n"]}],"source":["#create temp viw with latitude, longitude\n","complete_df.createOrReplaceTempView('lat_lon')\n","#select data from temp view\n","spark.sql('select latitudes, longitudes from lat_lon').show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NHvQ-DKqxVKk"},"outputs":[],"source":["#fazer um collect dos dados de latitude e longitude e buscar a previsão\n","#collect latitude, longitude data from temp view to loop through\n","dataCollect = spark.sql('select latitudes, longitudes from lat_lon').collect()\n","\n","latitudes = []\n","longitudes = []\n","\n","for city in dataCollect:\n","  latitudes.append(city['latitudes'])\n","  longitudes.append(city['longitudes'])\n","#print(latitudes, longitudes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QBI1e0xJyw8X"},"outputs":[],"source":["#get data from api using latitude and longitude coordinates\n","import itertools\n","raw_forecasts = []\n","\n","for lat, lon in zip(latitudes, longitudes):\n","\n","  get_coordinates = requests.get(f'http://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={API_KEY}&units=metric&lang=pt_br')\n","  raw_data = json.loads(get_coordinates.text)\n","  raw_forecasts.append(raw_data)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QowzY9HRS-SW","outputId":"e192240b-1c3d-4995-c415-d93b661141a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------+---------+---+------+----+--------+---------+-------+-------+--------+---------+---------+----------+---------+------+-----------+\n","\n","|cidade|codCidade|dia|regiao|pais|latitude|longitude|tempMax|tempMin|temMedia|vaiChover|pctgChuva|condiTempo|nascerSol|porSol|velMaxVento|\n","\n","+------+---------+---+------+----+--------+---------+-------+-------+--------+---------+---------+----------+---------+------+-----------+\n","\n","+------+---------+---+------+----+--------+---------+-------+-------+--------+---------+---------+----------+---------+------+-----------+\n","\n","\n"]}],"source":["#creates a dataframe with empty columns that will be filled when we get the city forecast\n","emptyRDD = spark.sparkContext.emptyRDD()\n","\n","schema = (StructType([\n","    StructField('cidade', StringType(), True),\n","    StructField('codCidade', StringType(), True),\n","    StructField('dia', StringType(), True),\n","    StructField('regiao', StringType(), True),\n","    StructField('pais', StringType(), True),\n","    StructField('latitude', StringType(), True),\n","    StructField('longitude', StringType(), True),\n","    StructField('tempMax', StringType(), True),\n","    StructField('tempMin', StringType(), True),\n","    StructField('temMedia', StringType(), True),\n","    StructField('vaiChover', StringType(), True),\n","    StructField('pctgChuva', StringType(), True),\n","    StructField('condiTempo', StringType(), True),\n","    StructField('nascerSol', StringType(), True),\n","    StructField('porSol', StringType(), True),\n","    StructField('velMaxVento', StringType(), True)\n","]))\n","df_forecast = spark.createDataFrame(emptyRDD, schema)\n","df_forecast.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Cme-VQg2oQW"},"outputs":[],"source":["#import datetime to convert the time from unix to tuc and then \n","import datetime\n","from datetime import timedelta\n","\n","#this 'for range' sets the predictions for the same time each day\n","for day in range (4, 44, 8):\n","  for forecast in raw_forecasts:\n","    vai_chover = ''\n","    if(str(forecast['list'][4]['weather'][0]['main']) == 'Rain'):\n","      vai_chover = \"Sim\"\n","\n","    #catches the time from unix time and converts to utc\n","    sunrise = datetime.datetime.fromtimestamp(raw_forecasts[1]['city']['sunrise'])\n","    #then subtracts -3 hours to match brasilia time\n","    sunrise -= timedelta(hours = 3)\n","    sunset = datetime.datetime.fromtimestamp(raw_forecasts[1]['city']['sunset'])\n","    sunset -= timedelta(hours = 3)\n","\n","    newRow = spark.createDataFrame([(\n","        forecast['city']['name'],\n","        forecast['city']['id'],\n","        forecast['list'][day]['dt_txt'],\n","        'Vale do Paraiba',\n","        forecast['city']['country'],\n","        forecast['city']['coord']['lat'],\n","        forecast['city']['coord']['lon'],\n","        forecast['list'][day]['main']['feels_like'],\n","        forecast['list'][day]['main']['temp'],\n","        forecast['list'][day]['main']['temp_min'],\n","        vai_chover,\n","        #forecast['list'][4]['weather'][0]['main'],\n","        int(forecast['list'][day]['pop']*100),\n","        forecast['list'][day]['weather'][0]['description'],\n","        sunrise,\n","        #forecast['city']['sunrise'],\n","        sunset,\n","        #forecast['city']['sunset'],\n","        forecast['list'][day]['wind']['speed'])])\n","\n","    df_forecast = df_forecast.union(newRow).distinct()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASv7T7h9Hvt2","outputId":"ef3692d9-838c-43eb-9ffd-b1125e28842b"},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n","\n","|cidade            |codCidade|dia                |regiao         |pais|latitude|longitude|tempMax|tempMin|temMedia|vaiChover|pctgChuva|condiTempo    |nascerSol          |porSol             |velMaxVento|\n","\n","+------------------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n","\n","|Aparecida         |3471949  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.69  |20.09  |20.09   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.5        |\n","\n","|Bananal           |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |22.41  |21.63  |21.63   |Sim      |82       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.3        |\n","\n","|Itatiaia          |3460602  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |21.97  |21.26  |21.26   |Sim      |93       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.69       |\n","\n","|Bananal           |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |22.64  |21.84  |21.84   |Sim      |76       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n","\n","|Caçapava          |3468562  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.0992|-45.7076 |20.33  |19.74  |19.74   |Sim      |96       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.62       |\n","\n","|Cachoeira Paulista|3468428  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6665|-45.0154 |21.44  |20.82  |20.82   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.5        |\n","\n","|Campos do Jordão  |3467684  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.7395|-45.5913 |14.15  |14.19  |14.19   |Sim      |97       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.71       |\n","\n","|Canas             |3467602  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.7029|-45.0527 |21.25  |20.65  |20.65   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.38       |\n","\n","|Caraguatatuba     |3467081  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.6203|-45.4131 |24.63  |23.75  |23.75   |Sim      |86       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|1.51       |\n","\n","|Cruzeiro          |3465090  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.5784|-44.9642 |21.81  |21.13  |21.13   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.88       |\n","\n","|Cunha             |3465010  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.0775|-44.9567 |18.54  |18.16  |18.16   |Sim      |93       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.48       |\n","\n","|Guaratinguetá     |3461859  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.8058|-45.1909 |20.74  |20.16  |20.16   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n","\n","|Igaratá           |3461495  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.2063|-46.1569 |19.79  |19.27  |19.27   |Sim      |88       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.91       |\n","\n","|Ilhabela          |3461425  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.8166|-45.3687 |25     |24.2   |24.2    |Sim      |75       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|1.9        |\n","\n","|Jacareí           |3460370  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.3053|-45.9658 |20.79  |20.18  |20.18   |Sim      |90       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|1.07       |\n","\n","|Jambeiro          |3460180  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.2556|-45.692  |19.66  |19.13  |19.13   |Sim      |92       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.76       |\n","\n","|Vargem Grande     |3445506  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.0898|-45.1904 |18.26  |17.88  |17.88   |Sim      |94       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.22       |\n","\n","|Lavrinhas         |3458681  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.57  |-44.9024 |21.93  |21.24  |21.24   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.89       |\n","\n","|Lorena            |3458425  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.7368|-45.1071 |21.06  |20.48  |20.48   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.39       |\n","\n","|Monteiro Lobato   |3456830  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.9554|-45.8387 |19.92  |19.39  |19.39   |Sim      |100      |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.86       |\n","\n","+------------------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n","\n","only showing top 20 rows\n","\n","\n"]}],"source":["#raw_forecasts[0]['city']\n","df_forecast.show(truncate = False)\n","#df_forecast.show()\n","\n","#dont know why but it is inserting in the dataframe duplicate values\n","#for city name but with different coordinate values and therefore different frecast for the same location"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywWcduaqgqMz","outputId":"4e0d35c6-f25e-4015-c4aa-460b467d4a4e"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n","\n","|cidade   |codCidade|dia                |regiao         |pais|latitude|longitude|tempMax|tempMin|temMedia|vaiChover|pctgChuva|condiTempo    |nascerSol          |porSol             |velMaxVento|\n","\n","+---------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n","\n","|Aparecida|3471949  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.69  |20.09  |20.09   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.5        |\n","\n","|Aparecida|3471949  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.87  |20.26  |20.26   |Sim      |10       |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.7        |\n","\n","|Aparecida|3471949  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |19.73  |19.24  |19.24   |Sim      |4        |algumas nuvens|2023-01-14 05:25:02|2023-01-14 18:48:01|1.09       |\n","\n","|Aparecida|3471949  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |19.22  |18.78  |18.78   |Sim      |69       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.91       |\n","\n","|Aparecida|3471949  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.35  |19.74  |19.74   |Sim      |100      |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.31       |\n","\n","|Arapeí   |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |22.41  |21.63  |21.63   |Sim      |82       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.3        |\n","\n","|Arapeí   |3470992  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |21.87  |21.14  |21.14   |Sim      |0        |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.34       |\n","\n","|Arapeí   |3470992  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |20.43  |19.86  |19.86   |Sim      |0        |algumas nuvens|2023-01-14 05:25:02|2023-01-14 18:48:01|0.31       |\n","\n","|Arapeí   |3470992  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |20.14  |19.59  |19.59   |Sim      |72       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.37       |\n","\n","|Arapeí   |3470992  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |20.94  |20.3   |20.3    |Sim      |99       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.47       |\n","\n","|Areias   |3460602  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |21.97  |21.26  |21.26   |Sim      |93       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.69       |\n","\n","|Areias   |3460602  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |21.38  |20.7   |20.7    |Sim      |0        |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.72       |\n","\n","|Areias   |3460602  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |20.16  |19.61  |19.61   |Sim      |0        |céu limpo     |2023-01-14 05:25:02|2023-01-14 18:48:01|0.79       |\n","\n","|Areias   |3460602  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |19.76  |19.27  |19.27   |Sim      |71       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.71       |\n","\n","|Areias   |3460602  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |20.68  |20.06  |20.06   |Sim      |97       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.69       |\n","\n","|Bananal  |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |22.64  |21.84  |21.84   |Sim      |76       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n","\n","|Bananal  |3470992  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |21.96  |21.22  |21.22   |Sim      |0        |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.47       |\n","\n","|Bananal  |3470992  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |20.49  |19.91  |19.91   |Sim      |0        |algumas nuvens|2023-01-14 05:25:02|2023-01-14 18:48:01|0.47       |\n","\n","|Bananal  |3470992  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |20.18  |19.63  |19.63   |Sim      |71       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n","\n","|Bananal  |3470992  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |21.07  |20.41  |20.41   |Sim      |99       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.77       |\n","\n","+---------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n","\n","only showing top 20 rows\n","\n","\n"]}],"source":["#for some reason the API is returning wrong city names for the given coordinates\n","#so i had to hardcode the correct cityname into the dataframe for those wrong coordinates\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.8377', 'Potim').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6739', 'Arapeí').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.5801', 'Areias').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6452', 'São José do Bareiro').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.5372', 'Queluz').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6638', 'Silveiras').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6885', 'São Bento do Sapucaí').otherwise(df_forecast['cidade']))\n","df_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-23.0898', 'Lagoinha').otherwise(df_forecast['cidade']))\n","df_forecast.sort(df_forecast.cidade.asc(), df_forecast.dia.asc()).show(truncate = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4JNIudxQQ8Kk"},"outputs":[],"source":["#rows = df_forecast.count()\n","#print(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5C08dJNb6Kf"},"outputs":[],"source":["#export ordered Table1 to csv with headers\n","df_forecast.orderBy('cidade').write.option('header', True).csv('Tabela_1_sorted.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dKI925UDjhkb"},"outputs":[],"source":["#this creates a temp view from df_forecast\n","df_forecast.createOrReplaceTempView('previsao')\n","#select data from temp view\n","previsao = spark.sql('select cidade, dia, tempMax, tempMin, temMedia,vaiChover, pctgChuva, velMaxVento from previsao order by cidade asc')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KysnxoAx7ZC0","outputId":"75f02839-ae45-4520-be0d-eba4ef735e08"},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+-------------------+-------+-------+--------+---------+---------+-----------+\n","\n","|cidade   |dia                |tempMax|tempMin|temMedia|vaiChover|pctgChuva|velMaxVento|\n","\n","+---------+-------------------+-------+-------+--------+---------+---------+-----------+\n","\n","|Aparecida|2023-01-15 06:00:00|20.69  |20.09  |20.09   |Sim      |96       |0.5        |\n","\n","|Aparecida|2023-01-16 06:00:00|20.87  |20.26  |20.26   |Sim      |10       |0.7        |\n","\n","|Aparecida|2023-01-17 06:00:00|19.73  |19.24  |19.24   |Sim      |4        |1.09       |\n","\n","|Aparecida|2023-01-18 06:00:00|19.22  |18.78  |18.78   |Sim      |69       |0.91       |\n","\n","|Aparecida|2023-01-19 06:00:00|20.35  |19.74  |19.74   |Sim      |100      |0.31       |\n","\n","|Arapeí   |2023-01-15 06:00:00|22.41  |21.63  |21.63   |Sim      |82       |0.3        |\n","\n","|Arapeí   |2023-01-16 06:00:00|21.87  |21.14  |21.14   |Sim      |0        |0.34       |\n","\n","|Arapeí   |2023-01-17 06:00:00|20.43  |19.86  |19.86   |Sim      |0        |0.31       |\n","\n","|Arapeí   |2023-01-18 06:00:00|20.14  |19.59  |19.59   |Sim      |72       |0.37       |\n","\n","|Arapeí   |2023-01-19 06:00:00|20.94  |20.3   |20.3    |Sim      |99       |0.47       |\n","\n","|Areias   |2023-01-15 06:00:00|21.97  |21.26  |21.26   |Sim      |93       |0.69       |\n","\n","|Areias   |2023-01-16 06:00:00|21.38  |20.7   |20.7    |Sim      |0        |0.72       |\n","\n","|Areias   |2023-01-17 06:00:00|20.16  |19.61  |19.61   |Sim      |0        |0.79       |\n","\n","|Areias   |2023-01-18 06:00:00|19.76  |19.27  |19.27   |Sim      |71       |0.71       |\n","\n","|Areias   |2023-01-19 06:00:00|20.68  |20.06  |20.06   |Sim      |97       |0.69       |\n","\n","|Bananal  |2023-01-15 06:00:00|22.64  |21.84  |21.84   |Sim      |76       |0.53       |\n","\n","|Bananal  |2023-01-16 06:00:00|21.96  |21.22  |21.22   |Sim      |0        |0.47       |\n","\n","|Bananal  |2023-01-17 06:00:00|20.49  |19.91  |19.91   |Sim      |0        |0.47       |\n","\n","|Bananal  |2023-01-18 06:00:00|20.18  |19.63  |19.63   |Sim      |71       |0.53       |\n","\n","|Bananal  |2023-01-19 06:00:00|21.07  |20.41  |20.41   |Sim      |99       |0.77       |\n","\n","+---------+-------------------+-------+-------+--------+---------+---------+-----------+\n","\n","only showing top 20 rows\n","\n","\n"]}],"source":["previsao.sort('cidade', 'dia').show(truncate = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yALXvTb9bpve"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cdc739f4-2ebf-4ff2-91ff-89689510e618","tags":[]},"outputs":[],"source":["# Buscar cidades do Vale do Paraíba\n","# Done\n","\n","# Criar data frame com as cidades\n","# Done\n","\n","# Criar view com as cidades\n","# Done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c4a40a6f-d5f1-4524-9d0b-d1e6e24dfbfa","tags":[]},"outputs":[],"source":["# Buscar previsão do tempo para as cidades\n","# Done\n","\n","# Criar data frame com as previsões\n","# Done\n","\n","# Criar view com as previsões\n","# Done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbc2a925-c707-46f0-a2e2-e0e0164a7312"},"outputs":[],"source":["# Criar DF da Tabela 1\n","# Done"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3bab3315-f50b-4269-8823-ccfda0fefbfe"},"outputs":[],"source":["# Criar DF da Tabela 2\n","# TODO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1ff378b-4c24-47dc-aba1-742211cd385d"},"outputs":[],"source":["# Exportar CSVs\n","# TODO"]},{"cell_type":"markdown","metadata":{"id":"DJQSfFPZJs6n"},"source":["#Ver se essa API vai tá funcionando amanhã, pode ser que ainda estava off"]},{"cell_type":"markdown","metadata":{"id":"g71O9GMyGcy2"},"source":["## Parei aqui\n","Tabela 2: quantidade de dias com chuva e sem chuva para os dias consultados, para cada data consultada. Colunas:\n","\n","Cidade\n","QtdDiasVaiChover\n","QtdDiasNaoVaiChover\n","TotalDiasMapeados"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
