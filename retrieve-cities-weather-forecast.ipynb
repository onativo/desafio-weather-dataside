{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Desafio: Consumo de Dados para Previsão do Tempo das Cidades do Vale do Paraíba.\n\n## Objetivo\n\nAvaliar conhecimentos nas linguagens Python e SQL e na engine de processamento Apache Spark.\n\n## Descrição\n\nNeste desafio, você desenvolverá um notebook que será responsável por extrair dados de previsão do tempo das cidades do Vale do Paraíba, região onde se localiza a Dataside. Para consultar todas as cidades dessa região, utilizaremos a API do IBGE. No caso, basta realizar uma requisição HTTP com o método GET, utilizando a URL abaixo:\n\n```\nhttps://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios\n```\n\nCom esses dados, gerar um data frame e a partir dele uma temp view. Ex: \"cities\"\n\nUtilizando os nomes das cidades, deverão ser consultados os dados de previsão de tempo para cada cidade. Para realizar essa consulta, poderá ser utilizada qualquer uma das APIs informadas no link abaixo.\n\n[Public APIs - Wather](https://github.com/public-apis/public-apis#weather)\n\nObs.: Para algumas, pode ser necessário cadastrar-se para acessar sua API Key. Mas nenhuma delas deve precisar cadastrar cartão de crédito ou adicionar qualquer valor monetário para utilizar. Caso alguma solicite, basta optar por outra.\n\nCom os dados consultados, gerar um data frame e partir dele outra temp view. Ex: \"forecasts\"\n\nCom as temp views geradas, utilizar Spark SQL para criar queries e gerar data frames das seguintes tabelas:\n\n- Tabela 1: dados de previsão do tempo para os próximos cinco dias, para cada data e cidade consultadas. As colunas dessa tabela serão:\n    - Cidade\n    - CodigoDaCidade\n    - Data\n    - Regiao\n    - Pais\n    - Latitude\n    - Longigute\n    - TemperaturaMaxima\n    - TemperaturaMinima\n    - TemperaturaMedia\n    - VaiChover\n    - ChanceDeChuva\n    - CondicaoDoTempo\n    - NascerDoSol\n    - PorDoSol\n    - VelocidadeMaximaDoVento\n    \n    Obs.: Os valores da coluna \"VaiChover\" deverá ser \"Sim\" ou \"Não\". E a coluna \"CodigoDaCidade\" é o ID retornado junto com os nomes da cidades na API do IBGE.\n    Obs.: Dependendo da API utilizada, algumas colunas podem não existir e ficarão em branco. Você deve optar por uma API que traga o maior número de informações possível.\n\n- Tabela 2: quantidade de dias com chuva e sem chuva para os dias consultados, para cada data consultada. Colunas:\n    - Cidade\n    - QtdDiasVaiChover\n    - QtdDiasNaoVaiChover\n    - TotalDiasMapeados\n\nEssas tabelas deverão ser exportadas em formado CSV e entregue no final do desafio.\n\n## To Do\n\n[ ] - Consultar municípios do Vale do Paraíba, gerar um data frame e criar uma temp view com esses dados.\n[ ] - Consultar dados do tempo para cada município, gerar um data frame e criar uma outra temp view.\n[ ] - Utilizar Spark SQL para gerar os data frames das Tabelas 1 e 2.\n[ ] - Exportar os data frames para CSV.\n\n## Atenção\n\n- Existe um limite de requisições de 10000 requests por conta cadastrada na m3o.\n- Essa API pode retornar cidades de outras regiões que possuem nome semelhante a alguma cidade do Vale do Paraiba. Pode mantê-las ou filtrar para gerar as tabelas apenas com dados de Regiao = Sao Paulo. Fica a seu critério.\n\n## Entregando o desafio\n\nConcluindo todos os passos informados em To Do, basta salvar o arquivo .ipynb do notebook e enviar para a Dataside juntamente com os CSVs das duas tabelas.\n","metadata":{"tags":[],"id":"580dd39c-f066-4c32-af47-648eb71f5918"}},{"cell_type":"code","source":"!pip install pyspark\n!pip install findspark\n!pip install unidecode","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jjfsduipH7tW","outputId":"b98ae981-c028-45e6-aaab-29e36cb95bed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n\nCollecting pyspark\n\n  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\nCollecting py4j==0.10.9.5\n\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hBuilding wheels for collected packages: pyspark\n\n  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n\n  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=a48b7d22dcd2b5a0948cc3b7bf20b941f354fdcfacaf75771af7184f5a5b79df\n\n  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n\nSuccessfully built pyspark\n\nInstalling collected packages: py4j, pyspark\n\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.1\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n\nCollecting findspark\n\n  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n\nInstalling collected packages: findspark\n\nSuccessfully installed findspark-2.0.1\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n\nCollecting unidecode\n\n  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\n\u001b[?25hInstalling collected packages: unidecode\n\nSuccessfully installed unidecode-1.3.6\n"}]},{"cell_type":"code","source":"import findspark\nfindspark.init()\n\nimport requests\nimport json\nimport unidecode\nimport ast\nimport pyspark\nfrom pyspark import SQLContext\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import StructType, StructField, StringType\n\n\n\nspark = SparkSession.builder \\\n      .master(\"local[1]\") \\\n      .appName(\"SparkByExamples.com\") \\\n      .getOrCreate()\nsparkContext = spark.sparkContext","metadata":{"tags":[],"id":"a1cb6c40-3073-43b0-b7f4-95e7c9dd8245"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#faz request na api e retorna json com dados\nr = requests.get('https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/3513/municipios')\n#verifica se 200 para sucesso\nr.status_code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOaPnVCgjlJM","outputId":"70b156bf-9ac5-4b5e-e788-52b7c11eae0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":["200"]},"metadata":{}}]},{"cell_type":"code","source":"#adiciona os dados retornados na variável cities\nraw_cities = r.json()","metadata":{"id":"Tu3qFVH1MmOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_cities[0].items()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cm7vIWDRB90G","outputId":"e4854232-ee5b-4fbe-9ba4-aea4107f9d86"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":["dict_items([('id', 3502507), ('nome', 'Aparecida'), ('microrregiao', {'id': 35051, 'nome': 'Guaratinguetá', 'mesorregiao': {'id': 3513, 'nome': 'Vale do Paraíba Paulista', 'UF': {'id': 35, 'sigla': 'SP', 'nome': 'São Paulo', 'regiao': {'id': 3, 'sigla': 'SE', 'nome': 'Sudeste'}}}}), ('regiao-imediata', {'id': 350052, 'nome': 'Guaratinguetá', 'regiao-intermediaria': {'id': 3511, 'nome': 'São José dos Campos', 'UF': {'id': 35, 'sigla': 'SP', 'nome': 'São Paulo', 'regiao': {'id': 3, 'sigla': 'SE', 'nome': 'Sudeste'}}}})])"]},"metadata":{}}]},{"cell_type":"code","source":"raw_cities[0]['id']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vQd6rI7Avcy","outputId":"095c2813-7be9-4124-a88c-284f57f7c063"},"execution_count":null,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":["3502507"]},"metadata":{}}]},{"cell_type":"code","source":"#cria dataframe com colunas para os dados da consulta\nemptyRDD = spark.sparkContext.emptyRDD()\n\nschemaDF1 = (StructType([\n    StructField('id', LongType(), True),\n    StructField('nome', StringType(), True),\n    StructField('microregiao', StringType(), True),\n    StructField('mesorregiao', StringType(), True),\n    StructField('UF', StringType(), True),\n    StructField('regiao', StringType(), True)\n]))\ndf = spark.createDataFrame(emptyRDD, schemaDF1)\ndf.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pklFxXx8CP6J","outputId":"f3f47575-9792-4efc-80ce-959aaf38fe8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+---+----+-----------+-----------+---+------+\n\n| id|nome|microregiao|mesorregiao| UF|regiao|\n\n+---+----+-----------+-----------+---+------+\n\n+---+----+-----------+-----------+---+------+\n\n\n"}]},{"cell_type":"code","source":"for city in raw_cities:\n  newRow = spark.createDataFrame([(city['id'],\n                                   city['nome'],\n                                   city['microrregiao']['nome'],\n                                   city['microrregiao']['mesorregiao']['nome'],\n                                   city['microrregiao']['mesorregiao']['UF']['sigla'],\n                                   city['microrregiao']['mesorregiao']['UF']['regiao']['nome']\n                                   )])\n  df = df.union(newRow)","metadata":{"id":"qo8xPYdMEi2n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.show(truncate = False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7L4nISOMNFI","outputId":"2a12645b-1552-4522-8ac7-2cbcb6a46e24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+-------+------------------+--------------------+------------------------+---+-------+\n\n|id     |nome              |microregiao         |mesorregiao             |UF |regiao |\n\n+-------+------------------+--------------------+------------------------+---+-------+\n\n|3502507|Aparecida         |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3503158|Arapeí            |Bananal             |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3503505|Areias            |Bananal             |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3504909|Bananal           |Bananal             |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3508504|Caçapava          |São José dos Campos |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3508603|Cachoeira Paulista|Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3509700|Campos do Jordão  |Campos do Jordão    |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3509957|Canas             |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3510500|Caraguatatuba     |Caraguatatuba       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3513405|Cruzeiro          |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3513603|Cunha             |Paraibuna/Paraitinga|Vale do Paraíba Paulista|SP |Sudeste|\n\n|3518404|Guaratinguetá     |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3520202|Igaratá           |São José dos Campos |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3520400|Ilhabela          |Caraguatatuba       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3524402|Jacareí           |São José dos Campos |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3524907|Jambeiro          |Paraibuna/Paraitinga|Vale do Paraíba Paulista|SP |Sudeste|\n\n|3526308|Lagoinha          |Paraibuna/Paraitinga|Vale do Paraíba Paulista|SP |Sudeste|\n\n|3526605|Lavrinhas         |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3527207|Lorena            |Guaratinguetá       |Vale do Paraíba Paulista|SP |Sudeste|\n\n|3531704|Monteiro Lobato   |Campos do Jordão    |Vale do Paraíba Paulista|SP |Sudeste|\n\n+-------+------------------+--------------------+------------------------+---+-------+\n\nonly showing top 20 rows\n\n\n"}]},{"cell_type":"code","source":"#create a temporary table view from original DataFrame\ndf.createOrReplaceTempView('cities')\n#select data from temp view\nspark.sql('select nome from cities').show()","metadata":{"id":"WuKa93Y2Gh0Y","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8db4dc7e-2c3b-4c37-ffa3-e7388d4b75d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+------------------+\n\n|              nome|\n\n+------------------+\n\n|         Aparecida|\n\n|            Arapeí|\n\n|            Areias|\n\n|           Bananal|\n\n|          Caçapava|\n\n|Cachoeira Paulista|\n\n|  Campos do Jordão|\n\n|             Canas|\n\n|     Caraguatatuba|\n\n|          Cruzeiro|\n\n|             Cunha|\n\n|     Guaratinguetá|\n\n|           Igaratá|\n\n|          Ilhabela|\n\n|           Jacareí|\n\n|          Jambeiro|\n\n|          Lagoinha|\n\n|         Lavrinhas|\n\n|            Lorena|\n\n|   Monteiro Lobato|\n\n+------------------+\n\nonly showing top 20 rows\n\n\n"}]},{"cell_type":"code","source":"#collect data from temp view to loop through\ndataCollect = spark.sql('select nome from cities').collect()\ncities_name = []\n\n#stores the names of the cities in the cities_name list to pass to API\nfor city in dataCollect:\n  cities_name.append(city['nome'])\n  \nprint(cities_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAz5gXxIat3S","outputId":"4d717dcb-e098-4c00-8c51-29c0e070c3fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"['Aparecida', 'Arapeí', 'Areias', 'Bananal', 'Caçapava', 'Cachoeira Paulista', 'Campos do Jordão', 'Canas', 'Caraguatatuba', 'Cruzeiro', 'Cunha', 'Guaratinguetá', 'Igaratá', 'Ilhabela', 'Jacareí', 'Jambeiro', 'Lagoinha', 'Lavrinhas', 'Lorena', 'Monteiro Lobato', 'Natividade da Serra', 'Paraibuna', 'Pindamonhangaba', 'Piquete', 'Potim', 'Queluz', 'Redenção da Serra', 'Roseira', 'Santa Branca', 'Santo Antônio do Pinhal', 'São Bento do Sapucaí', 'São José do Barreiro', 'São José dos Campos', 'São Luiz do Paraitinga', 'São Sebastião', 'Silveiras', 'Taubaté', 'Tremembé', 'Ubatuba']\n"}]},{"cell_type":"code","source":"API_KEY = '527fe89bf79a34efb642a61cc5990eb6'\nlatitudes = []\nlongitudes = []\n\n#get city latitude and longitude from city name and state code\nfor city in cities_name:\n  get_coordinates = requests.get(f'http://api.openweathermap.org/geo/1.0/direct?q={city},BR&limit=5&appid={API_KEY}')\n  raw_data = json.loads(get_coordinates.text)\n   \n  latitudes.append(raw_data[0]['lat'])\n  longitudes.append(raw_data[0]['lon'])\n\n#link_api = f'api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={API_KEY}'","metadata":{"id":"ADTLe7cmX-ko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#convert list of latitudes to a dataframe\nlatitudes_data = spark.createDataFrame([(lat,) for lat in latitudes], ['latitudes'])\n\n#convert list longitudes to a dataframe\nlongitudes_data = spark.createDataFrame([(lon,) for lon in longitudes], ['longitudes'])","metadata":{"id":"7e3OEq98YgoS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql.functions import monotonically_increasing_id, row_number\nfrom pyspark.sql import Window\n\n#add sequential index and join both dataframes to get intermediary result\nlatitudes_data = latitudes_data.withColumn(\"index\", row_number().over(Window.orderBy(monotonically_increasing_id())))\nlongitudes_data = longitudes_data.withColumn(\"index\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n\n#intermediary result of both latitude and longitude dataframes\nintermediary_df = latitudes_data.join(longitudes_data, latitudes_data.index == longitudes_data.index).drop('index')\n\n#intermediary_df.show()","metadata":{"id":"pF2HJ8DEZdHB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now, to join the main df to the intermediary_df\n\n#add sequential index in both dataframes\ndf = df.withColumn('index', row_number().over(Window.orderBy(monotonically_increasing_id())))\nintermediary_df = intermediary_df.withColumn('index', row_number().over(Window.orderBy(monotonically_increasing_id())))\n\n#final result\ncomplete_df = df.join(intermediary_df, df.index == intermediary_df.index).drop('index')\n\n#complete_df.show(truncate = False)","metadata":{"id":"i91MkQCwaTYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#rows = complete_df.count()\n#print(rows)","metadata":{"id":"q4cqG7f3shPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create temp viw with latitude, longitude\ncomplete_df.createOrReplaceTempView('lat_lon')\n#select data from temp view\nspark.sql('select latitudes, longitudes from lat_lon').show()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sqx8G453bCIA","outputId":"424d61e6-04d2-4a15-eb50-425e949ccc64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+-----------+-----------+\n\n|  latitudes| longitudes|\n\n+-----------+-----------+\n\n| -22.851552|-45.2340924|\n\n|-22.6738889|-44.4477778|\n\n|-22.5800929|-44.6975127|\n\n|-22.6828195|-44.3221095|\n\n| -23.099204| -45.707645|\n\n| -22.666498| -45.015384|\n\n|-22.7395263|-45.5912829|\n\n|-22.7029347|-45.0526508|\n\n|  -23.62028|  -45.41306|\n\n|-22.5783685|-44.9642044|\n\n|  -23.07753|-44.9567436|\n\n|-22.8057839|-45.1908926|\n\n|-23.2063475| -46.156934|\n\n| -23.816628| -45.368685|\n\n|  -23.30528|  -45.96583|\n\n|-23.2556416|-45.6919926|\n\n|-23.0898337|-45.1903825|\n\n| -22.570047| -44.902359|\n\n|-22.7367652|-45.1070876|\n\n|-22.9553542|-45.8387146|\n\n+-----------+-----------+\n\nonly showing top 20 rows\n\n\n"}]},{"cell_type":"code","source":"#fazer um collect dos dados de latitude e longitude e buscar a previsão\n#collect latitude, longitude data from temp view to loop through\ndataCollect = spark.sql('select latitudes, longitudes from lat_lon').collect()\n\nlatitudes = []\nlongitudes = []\n\nfor city in dataCollect:\n  latitudes.append(city['latitudes'])\n  longitudes.append(city['longitudes'])\n#print(latitudes, longitudes)","metadata":{"id":"NHvQ-DKqxVKk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get data from api using latitude and longitude coordinates\nimport itertools\nraw_forecasts = []\n\nfor lat, lon in zip(latitudes, longitudes):\n\n  get_coordinates = requests.get(f'http://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&appid={API_KEY}&units=metric&lang=pt_br')\n  raw_data = json.loads(get_coordinates.text)\n  raw_forecasts.append(raw_data)\n\n","metadata":{"id":"QBI1e0xJyw8X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creates a dataframe with empty columns that will be filled when we get the city forecast\nemptyRDD = spark.sparkContext.emptyRDD()\n\nschema = (StructType([\n    StructField('cidade', StringType(), True),\n    StructField('codCidade', StringType(), True),\n    StructField('dia', StringType(), True),\n    StructField('regiao', StringType(), True),\n    StructField('pais', StringType(), True),\n    StructField('latitude', StringType(), True),\n    StructField('longitude', StringType(), True),\n    StructField('tempMax', StringType(), True),\n    StructField('tempMin', StringType(), True),\n    StructField('temMedia', StringType(), True),\n    StructField('vaiChover', StringType(), True),\n    StructField('pctgChuva', StringType(), True),\n    StructField('condiTempo', StringType(), True),\n    StructField('nascerSol', StringType(), True),\n    StructField('porSol', StringType(), True),\n    StructField('velMaxVento', StringType(), True)\n]))\ndf_forecast = spark.createDataFrame(emptyRDD, schema)\ndf_forecast.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QowzY9HRS-SW","outputId":"e192240b-1c3d-4995-c415-d93b661141a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+------+---------+---+------+----+--------+---------+-------+-------+--------+---------+---------+----------+---------+------+-----------+\n\n|cidade|codCidade|dia|regiao|pais|latitude|longitude|tempMax|tempMin|temMedia|vaiChover|pctgChuva|condiTempo|nascerSol|porSol|velMaxVento|\n\n+------+---------+---+------+----+--------+---------+-------+-------+--------+---------+---------+----------+---------+------+-----------+\n\n+------+---------+---+------+----+--------+---------+-------+-------+--------+---------+---------+----------+---------+------+-----------+\n\n\n"}]},{"cell_type":"code","source":"#import datetime to convert the time from unix to tuc and then \nimport datetime\nfrom datetime import timedelta\n\n#this 'for range' sets the predictions for the same time each day\nfor day in range (4, 44, 8):\n  for forecast in raw_forecasts:\n    vai_chover = ''\n    if(str(forecast['list'][4]['weather'][0]['main']) == 'Rain'):\n      vai_chover = \"Sim\"\n\n    #catches the time from unix time and converts to utc\n    sunrise = datetime.datetime.fromtimestamp(raw_forecasts[1]['city']['sunrise'])\n    #then subtracts -3 hours to match brasilia time\n    sunrise -= timedelta(hours = 3)\n    sunset = datetime.datetime.fromtimestamp(raw_forecasts[1]['city']['sunset'])\n    sunset -= timedelta(hours = 3)\n\n    newRow = spark.createDataFrame([(\n        forecast['city']['name'],\n        forecast['city']['id'],\n        forecast['list'][day]['dt_txt'],\n        'Vale do Paraiba',\n        forecast['city']['country'],\n        forecast['city']['coord']['lat'],\n        forecast['city']['coord']['lon'],\n        forecast['list'][day]['main']['feels_like'],\n        forecast['list'][day]['main']['temp'],\n        forecast['list'][day]['main']['temp_min'],\n        vai_chover,\n        #forecast['list'][4]['weather'][0]['main'],\n        int(forecast['list'][day]['pop']*100),\n        forecast['list'][day]['weather'][0]['description'],\n        sunrise,\n        #forecast['city']['sunrise'],\n        sunset,\n        #forecast['city']['sunset'],\n        forecast['list'][day]['wind']['speed'])])\n\n    df_forecast = df_forecast.union(newRow).distinct()","metadata":{"id":"4Cme-VQg2oQW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#raw_forecasts[0]['city']\ndf_forecast.show(truncate = False)\n#df_forecast.show()\n\n#dont know why but it is inserting in the dataframe duplicate values\n#for city name but with different coordinate values and therefore different frecast for the same location","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASv7T7h9Hvt2","outputId":"ef3692d9-838c-43eb-9ffd-b1125e28842b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+------------------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n\n|cidade            |codCidade|dia                |regiao         |pais|latitude|longitude|tempMax|tempMin|temMedia|vaiChover|pctgChuva|condiTempo    |nascerSol          |porSol             |velMaxVento|\n\n+------------------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n\n|Aparecida         |3471949  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.69  |20.09  |20.09   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.5        |\n\n|Bananal           |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |22.41  |21.63  |21.63   |Sim      |82       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.3        |\n\n|Itatiaia          |3460602  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |21.97  |21.26  |21.26   |Sim      |93       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.69       |\n\n|Bananal           |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |22.64  |21.84  |21.84   |Sim      |76       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n\n|Caçapava          |3468562  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.0992|-45.7076 |20.33  |19.74  |19.74   |Sim      |96       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.62       |\n\n|Cachoeira Paulista|3468428  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6665|-45.0154 |21.44  |20.82  |20.82   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.5        |\n\n|Campos do Jordão  |3467684  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.7395|-45.5913 |14.15  |14.19  |14.19   |Sim      |97       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.71       |\n\n|Canas             |3467602  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.7029|-45.0527 |21.25  |20.65  |20.65   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.38       |\n\n|Caraguatatuba     |3467081  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.6203|-45.4131 |24.63  |23.75  |23.75   |Sim      |86       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|1.51       |\n\n|Cruzeiro          |3465090  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.5784|-44.9642 |21.81  |21.13  |21.13   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.88       |\n\n|Cunha             |3465010  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.0775|-44.9567 |18.54  |18.16  |18.16   |Sim      |93       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.48       |\n\n|Guaratinguetá     |3461859  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.8058|-45.1909 |20.74  |20.16  |20.16   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n\n|Igaratá           |3461495  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.2063|-46.1569 |19.79  |19.27  |19.27   |Sim      |88       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.91       |\n\n|Ilhabela          |3461425  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.8166|-45.3687 |25     |24.2   |24.2    |Sim      |75       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|1.9        |\n\n|Jacareí           |3460370  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.3053|-45.9658 |20.79  |20.18  |20.18   |Sim      |90       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|1.07       |\n\n|Jambeiro          |3460180  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.2556|-45.692  |19.66  |19.13  |19.13   |Sim      |92       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.76       |\n\n|Vargem Grande     |3445506  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-23.0898|-45.1904 |18.26  |17.88  |17.88   |Sim      |94       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.22       |\n\n|Lavrinhas         |3458681  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.57  |-44.9024 |21.93  |21.24  |21.24   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.89       |\n\n|Lorena            |3458425  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.7368|-45.1071 |21.06  |20.48  |20.48   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.39       |\n\n|Monteiro Lobato   |3456830  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.9554|-45.8387 |19.92  |19.39  |19.39   |Sim      |100      |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.86       |\n\n+------------------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n\nonly showing top 20 rows\n\n\n"}]},{"cell_type":"code","source":"#for some reason the API is returning wrong city names for the given coordinates\n#so i had to hardcode the correct cityname into the dataframe for those wrong coordinates\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.8377', 'Potim').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6739', 'Arapeí').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.5801', 'Areias').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6452', 'São José do Bareiro').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.5372', 'Queluz').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6638', 'Silveiras').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-22.6885', 'São Bento do Sapucaí').otherwise(df_forecast['cidade']))\ndf_forecast = df_forecast.withColumn('cidade', pyspark.sql.functions.when(df_forecast['latitude'] == '-23.0898', 'Lagoinha').otherwise(df_forecast['cidade']))\ndf_forecast.sort(df_forecast.cidade.asc(), df_forecast.dia.asc()).show(truncate = False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywWcduaqgqMz","outputId":"4e0d35c6-f25e-4015-c4aa-460b467d4a4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+---------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n\n|cidade   |codCidade|dia                |regiao         |pais|latitude|longitude|tempMax|tempMin|temMedia|vaiChover|pctgChuva|condiTempo    |nascerSol          |porSol             |velMaxVento|\n\n+---------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n\n|Aparecida|3471949  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.69  |20.09  |20.09   |Sim      |96       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.5        |\n\n|Aparecida|3471949  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.87  |20.26  |20.26   |Sim      |10       |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.7        |\n\n|Aparecida|3471949  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |19.73  |19.24  |19.24   |Sim      |4        |algumas nuvens|2023-01-14 05:25:02|2023-01-14 18:48:01|1.09       |\n\n|Aparecida|3471949  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |19.22  |18.78  |18.78   |Sim      |69       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.91       |\n\n|Aparecida|3471949  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.8516|-45.2341 |20.35  |19.74  |19.74   |Sim      |100      |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.31       |\n\n|Arapeí   |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |22.41  |21.63  |21.63   |Sim      |82       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.3        |\n\n|Arapeí   |3470992  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |21.87  |21.14  |21.14   |Sim      |0        |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.34       |\n\n|Arapeí   |3470992  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |20.43  |19.86  |19.86   |Sim      |0        |algumas nuvens|2023-01-14 05:25:02|2023-01-14 18:48:01|0.31       |\n\n|Arapeí   |3470992  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |20.14  |19.59  |19.59   |Sim      |72       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.37       |\n\n|Arapeí   |3470992  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.6739|-44.4478 |20.94  |20.3   |20.3    |Sim      |99       |chuva moderada|2023-01-14 05:25:02|2023-01-14 18:48:01|0.47       |\n\n|Areias   |3460602  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |21.97  |21.26  |21.26   |Sim      |93       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.69       |\n\n|Areias   |3460602  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |21.38  |20.7   |20.7    |Sim      |0        |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.72       |\n\n|Areias   |3460602  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |20.16  |19.61  |19.61   |Sim      |0        |céu limpo     |2023-01-14 05:25:02|2023-01-14 18:48:01|0.79       |\n\n|Areias   |3460602  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |19.76  |19.27  |19.27   |Sim      |71       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.71       |\n\n|Areias   |3460602  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.5801|-44.6975 |20.68  |20.06  |20.06   |Sim      |97       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.69       |\n\n|Bananal  |3470992  |2023-01-15 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |22.64  |21.84  |21.84   |Sim      |76       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n\n|Bananal  |3470992  |2023-01-16 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |21.96  |21.22  |21.22   |Sim      |0        |nublado       |2023-01-14 05:25:02|2023-01-14 18:48:01|0.47       |\n\n|Bananal  |3470992  |2023-01-17 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |20.49  |19.91  |19.91   |Sim      |0        |algumas nuvens|2023-01-14 05:25:02|2023-01-14 18:48:01|0.47       |\n\n|Bananal  |3470992  |2023-01-18 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |20.18  |19.63  |19.63   |Sim      |71       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.53       |\n\n|Bananal  |3470992  |2023-01-19 06:00:00|Vale do Paraiba|BR  |-22.6828|-44.3221 |21.07  |20.41  |20.41   |Sim      |99       |chuva leve    |2023-01-14 05:25:02|2023-01-14 18:48:01|0.77       |\n\n+---------+---------+-------------------+---------------+----+--------+---------+-------+-------+--------+---------+---------+--------------+-------------------+-------------------+-----------+\n\nonly showing top 20 rows\n\n\n"}]},{"cell_type":"code","source":"#rows = df_forecast.count()\n#print(rows)","metadata":{"id":"4JNIudxQQ8Kk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#export ordered Table1 to csv with headers\ndf_forecast.orderBy('cidade').write.option('header', True).csv('Tabela_1_sorted.csv')","metadata":{"id":"P5C08dJNb6Kf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this creates a temp view from df_forecast\ndf_forecast.createOrReplaceTempView('previsao')\n#select data from temp view\nprevisao = spark.sql('select cidade, dia, tempMax, tempMin, temMedia,vaiChover, pctgChuva, velMaxVento from previsao order by cidade asc')","metadata":{"id":"dKI925UDjhkb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"previsao.sort('cidade', 'dia').show(truncate = False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KysnxoAx7ZC0","outputId":"75f02839-ae45-4520-be0d-eba4ef735e08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":"+---------+-------------------+-------+-------+--------+---------+---------+-----------+\n\n|cidade   |dia                |tempMax|tempMin|temMedia|vaiChover|pctgChuva|velMaxVento|\n\n+---------+-------------------+-------+-------+--------+---------+---------+-----------+\n\n|Aparecida|2023-01-15 06:00:00|20.69  |20.09  |20.09   |Sim      |96       |0.5        |\n\n|Aparecida|2023-01-16 06:00:00|20.87  |20.26  |20.26   |Sim      |10       |0.7        |\n\n|Aparecida|2023-01-17 06:00:00|19.73  |19.24  |19.24   |Sim      |4        |1.09       |\n\n|Aparecida|2023-01-18 06:00:00|19.22  |18.78  |18.78   |Sim      |69       |0.91       |\n\n|Aparecida|2023-01-19 06:00:00|20.35  |19.74  |19.74   |Sim      |100      |0.31       |\n\n|Arapeí   |2023-01-15 06:00:00|22.41  |21.63  |21.63   |Sim      |82       |0.3        |\n\n|Arapeí   |2023-01-16 06:00:00|21.87  |21.14  |21.14   |Sim      |0        |0.34       |\n\n|Arapeí   |2023-01-17 06:00:00|20.43  |19.86  |19.86   |Sim      |0        |0.31       |\n\n|Arapeí   |2023-01-18 06:00:00|20.14  |19.59  |19.59   |Sim      |72       |0.37       |\n\n|Arapeí   |2023-01-19 06:00:00|20.94  |20.3   |20.3    |Sim      |99       |0.47       |\n\n|Areias   |2023-01-15 06:00:00|21.97  |21.26  |21.26   |Sim      |93       |0.69       |\n\n|Areias   |2023-01-16 06:00:00|21.38  |20.7   |20.7    |Sim      |0        |0.72       |\n\n|Areias   |2023-01-17 06:00:00|20.16  |19.61  |19.61   |Sim      |0        |0.79       |\n\n|Areias   |2023-01-18 06:00:00|19.76  |19.27  |19.27   |Sim      |71       |0.71       |\n\n|Areias   |2023-01-19 06:00:00|20.68  |20.06  |20.06   |Sim      |97       |0.69       |\n\n|Bananal  |2023-01-15 06:00:00|22.64  |21.84  |21.84   |Sim      |76       |0.53       |\n\n|Bananal  |2023-01-16 06:00:00|21.96  |21.22  |21.22   |Sim      |0        |0.47       |\n\n|Bananal  |2023-01-17 06:00:00|20.49  |19.91  |19.91   |Sim      |0        |0.47       |\n\n|Bananal  |2023-01-18 06:00:00|20.18  |19.63  |19.63   |Sim      |71       |0.53       |\n\n|Bananal  |2023-01-19 06:00:00|21.07  |20.41  |20.41   |Sim      |99       |0.77       |\n\n+---------+-------------------+-------+-------+--------+---------+---------+-----------+\n\nonly showing top 20 rows\n\n\n"}]},{"cell_type":"code","source":"","metadata":{"id":"yALXvTb9bpve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Buscar cidades do Vale do Paraíba\n# Done\n\n# Criar data frame com as cidades\n# Done\n\n# Criar view com as cidades\n# Done","metadata":{"tags":[],"id":"cdc739f4-2ebf-4ff2-91ff-89689510e618"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Buscar previsão do tempo para as cidades\n# Done\n\n# Criar data frame com as previsões\n# Done\n\n# Criar view com as previsões\n# Done","metadata":{"tags":[],"id":"c4a40a6f-d5f1-4524-9d0b-d1e6e24dfbfa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Criar DF da Tabela 1\n# Done","metadata":{"id":"bbc2a925-c707-46f0-a2e2-e0e0164a7312"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Criar DF da Tabela 2\n# TODO","metadata":{"id":"3bab3315-f50b-4269-8823-ccfda0fefbfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Exportar CSVs\n# TODO","metadata":{"id":"c1ff378b-4c24-47dc-aba1-742211cd385d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Ver se essa API vai tá funcionando amanhã, pode ser que ainda estava off","metadata":{"id":"DJQSfFPZJs6n"}},{"cell_type":"markdown","source":"## Parei aqui\nTabela 2: quantidade de dias com chuva e sem chuva para os dias consultados, para cada data consultada. Colunas:\n\nCidade\nQtdDiasVaiChover\nQtdDiasNaoVaiChover\nTotalDiasMapeados","metadata":{"id":"g71O9GMyGcy2"}}]}